---
title: "Testing"
author: "Justin L"
date: "4/4/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
library(ggplot2)
library(magrittr)
library(tidyr)
library(dplyr)
library(justinmisc)
library(reshape2)
library(aiR)
# library(gapminder)
# library(gganimate)
# library(animation)
```

```{r}
#Training data 1

set.seed(6227)
group1.x <- runif(n = 4200)
group1.y <- runif(n = 4200)
group2.x <- runif(n = 4200, min = -1, max = .5)
group2.y <- runif(n = 4200, min = -1, max = .1)

g1 <- cbind(group1.x,group1.y, rep("g1",4200))
colnames(g1) <- c("x","y","group")
g2 <- cbind(group2.x,group2.y, rep("g2",4200))
colnames(g2) <- c("x","y","group")

train <- as.data.frame(rbind(g1,g2))
train <- justinmisc::correct.mode(train,c("num","num","Factor"))
#train$z <- runif(300)
ggplot(train, aes(x,y, color = group)) +
  geom_point()

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}

mylayers <- aiRnet(c(2,4,4,2))
# layer1 <- aiRlayer(2,4)
# layer2 <- aiRlayer(4,2)
# mylayers <- list(layer1, layer2)
```


```{r}
# train <- rbind(train, data.frame(x = c(.7, .9, .6, -.7,-.9,-.6),
#                         y = c(-.7,-.6,-.9, .5, .3, .8),
#                         group = c("g2","g2","g2","g1","g1","g1"),
#                         z = c(.1,.2,.4,.5,.7,-.8)))
train <- train[,-4]
loss.aiR <- aiRrun(data = train,var.classify = "group",aiRnet = mylayers, sample.size = 1,cycles = 300,batch.size = 30)

```

```{r}
set.seed(6778)
system.time(loss.aiR <- aiRrun(data = train,var.classify = "group",aiRnet = mylayers, sample.size = .5,cycles = 300,batch.size = 60))
set.seed(6778)
system.time(loss.aiR <- aiRrun(data = train,var.classify = "group",aiRnet = mylayers, sample.size = .5,cycles = 300,batch.size = 60, test = TRUE))
```





```{r}
iteration <- as.numeric(rownames(loss.aiR$loss))
ggplot(data = loss.aiR$loss,aes(x = iteration)) +
  geom_point(aes(y = train,color = "train")) +
  geom_point(aes(y = train.error, color = "train.error")) +
  #geom_point(aes(y = test, color = "test")) +
  labs(list(y = "loss"))+
  coord_cartesian(ylim = c(min(loss.aiR$loss[!loss.aiR$loss==0]),max(loss.aiR$loss)))+
  theme(axis.text.x = element_text(angle = 90)) +
  scale_y_log10()
```



```{r}
# v <- function(data,
#               factor,
#               aiRnet,
#               range.size = 10000) {
#   index <- index.o.coln(vec = factor, v.size = 1, v.name = "factor", name.col = colnames(data))
#   new <- aiRactivation(data = data[,-index], aiRnet = aiRnet, range.size = range.size)
#   classify_obj <- aiRclassify(data = new$data_model, factor = index, aiRnet = aiRnet)
#   gg <- ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
#   geom_point(aes(color = as.factor(classify_obj$classify), alpha = classify_obj$node.max))
#   return(gg)
#               }
```

```{r}
new <- aiRactivation(data = train[,-3], aiRnet = loss.aiR$aiRnet, range.size = 10000)

```

```{r}
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = as.factor(classify_obj$classify), alpha = classify_obj$node.max)) 
```

```{r}
aiRrate(data = train, factor = "group", layers = loss.aiR$layers)
```

```{r}
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer1[,1])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer1[,2])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer1[,3])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer1[,4])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
```
```{r}
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer2[,1])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer2[,2])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
```


```{r}
classify_obj <- aiRclassify(data = new$data_model, factor = levels(train$group), aiRnet = loss.aiR$aiRnet)
```

```{r}
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = as.factor(classify_obj$classify), alpha = classify_obj$node.max)) 
```

```{r}
aiRrate(data = train, factor = "group", aiRnet = loss.aiR$aiRnet)
```


```{r}
space.var <- aiRdevelop(data = train, var.classify = "group", aiRnet = mylayers, sample.size = 1, batch.size = 60, steps = 22)
  gg <- ggplot(data = space.var, aes(x = x, y = y, color = classify, alpha = node.max)) +
    geom_point() +
    facet_wrap(~step)
  gg

```

```{r}
train_additional <- data.frame(x = c(runif(n = 600,min = -1,0),runif(n = 600, min = 0, 1)), y = c(runif(n = 600,min = 0,1),runif(n = 600, min = -1, 0)), group = as.factor(rep(c("g3","g4"), each = 600)))
```

```{r}
#build > load all
newaiR <- aiRnet(c(2,50,50,6,4))
aiRnet1 <- newaiR
aiRnet2 <- newaiR
t <- length(aiRnet1)
s <- 5000
try.test <- rbind(train, train_additional)
try.test <- try.test[sample(1:nrow(try.test),size = s),]



loss <- aiRloss(data = aiRtransform(data = try.test[,-3], aiRnet = aiRnet1),class.levels = levels(try.test[,3]),classify = try.test[,3])
additional.c <- apply(loss$loss.prop*abs(loss$loss.prop),2,mean)/((apply(loss$loss.prop,2,mean)*abs(apply(loss$loss.prop,2,mean))))  # The proportion mean of squares to square of mean... (iteration of each row vs average each row)
.app <- apply(loss$loss.prop,2, mean)
.row.work <- additional.c*sqrt(length(.app))*.app*(abs(.app/(loss$total.loss)))
w <- mat.opperation(x = abs(aiRnet2[[t]]$weights), y = .row.work, opperation = "*")

system.time(aiRnet1 <- test1())
   


# aiRnet2 <- aiRrowdelta2(loss.prop = loss$loss.prop,
#                        total.loss = loss$total.loss,
#                        aiRnet = aiRnet2,
#                        n = t, data = try.test, index = 3)
#system.time(aiRnet2 <- test2(aiRnet2 = aiRnet2))
system.time(aiRnet2 <- test3())

table(try.test$group)
mult.w <- abs(aiRnet2[[t]]$change.w/w)
mult.w[1,]
mult.w <- sum(mult.w[1,]*(apply(abs(loss$loss.prop),2,sum)/(sum(apply(abs(loss$loss.prop),2,sum)))))
aiRnet2[[t]]$change.w <- w
#mult.w <- mean(mult.w[1,])
#mult.w <- mult.w[1,apply(abs(loss$loss.prop),2,sum)/(sum(apply(abs(loss$loss.prop),2,sum))) == max(apply(abs(loss$loss.prop),2,sum)/(sum(apply(abs(loss$loss.prop),2,sum))))]
for(a in 1:(t-1)) {
  aiRnet2[[a]]$change.w <- aiRnet2[[a]]$change.w/mult.w
}

for(i in t:1) {
  print((aiRnet1[[i]]$change.w/aiRnet2[[i]]$change.w)[1,])
}

```

```{r}
aiRrowdelta2 <- function(loss.prop,
                        total.loss,
                        aiRnet,
                        n,
                        data,
                        index) {
  

  #g <- nrow(loss.prop)
  row.work <- apply(loss.prop,2,mean)
  additional.c <- apply(loss.prop*abs(loss.prop),2,mean)/((apply(loss.prop,2,mean)*abs(apply(loss.prop,2,mean))))
  #row.work <- additional.c*sqrt(length(row.work))*row.work*(abs(row.work/(total.loss)))
  row.work <- additional.c*sqrt(length(row.work))*row.work*(abs(row.work/(total.loss)))
  for(j in n:1) { #use back propigation... record desired changes for each input to each node... record in $change.w $change.b
    w <- mat.opperation(x = abs(aiRnet[[j]]$weights), y = row.work, opperation = "*")
    aiRnet[[j]]$change.w <- aiRnet[[j]]$change.w + w
    b <- abs(aiRnet[[j]]$bias)*row.work
    aiRnet[[j]]$change.b <- aiRnet[[j]]$change.b + b
    new.loss <- apply(w,1,mean)
    if(j!=1) {
      data.work <- aiRtransform(data = data[,-index], aiRnet = aiRnet, n = j-1)
      new.loss <- sqrt(length(new.loss))*new.loss*(abs(new.loss))/(sum(abs(new.loss)))
      loss.work <- mat.opperation(x = as.matrix(data.work), y = new.loss, opperation = "*")
      new.loss <- apply(loss.work, 2, mean)
      additional.c <- apply(loss.work*abs(loss.work),2,mean)/((apply(loss.work,2,mean)*abs(apply(loss.work,2,mean))))
    #additional.c <- apply(as.data.frame(w)*abs(as.data.frame(w)),1,mean)/((apply(as.data.frame(w),1,mean)*abs(apply(as.data.frame(w),1,mean))))
    row.work <- additional.c*sqrt(length(new.loss))*new.loss*(abs(new.loss)/sum(abs(new.loss)))
    }
    
  }
  return(aiRnet)
}
```

```{r}
aiRrowdelta1 <- function(loss.prop,
                        total.loss,
                        aiRnet,
                        n) {
  #g <- nrow(loss.prop)
  #row.work <- apply(loss.prop,2,mean)
  #additional.c <- apply(loss.prop*abs(loss.prop),2,mean)/((apply(loss.prop,2,mean)*abs(apply(loss.prop,2,mean))))
  #row.work <- additional.c*sqrt(length(row.work))*row.work*(abs(row.work/(total.loss)))
  row.work <- sqrt(length(loss.prop))*loss.prop*(abs(loss.prop/(total.loss)))
  for(j in n:1) { #use back propigation... record desired changes for each input to each node... record in $change.w $change.b
    w <- mat.opperation(x = abs(aiRnet[[j]]$weights), y = row.work, opperation = "*")
    aiRnet[[j]]$change.w <- aiRnet[[j]]$change.w + w
    b <- abs(aiRnet[[j]]$bias)*row.work
    aiRnet[[j]]$change.b <- aiRnet[[j]]$change.b + b
    new.loss <- apply(w,1,mean)
    #additional.c <- (sum(apply(loss.prop,2,mean)^2))*(sum(abs(apply(loss.prop^2,1,sum)))/(g*(sum(apply(loss$loss.prop^2,1,sum)*abs(apply(loss$loss.prop^2,1,sum))))))
    row.work <- sqrt(length(new.loss))*new.loss*(abs(new.loss)/sum(abs(new.loss)))
  }
  return(aiRnet)
}
```

```{r}
test_func <- function(x) {
  print(abs(x[1]*x[3]+x[2]*x[4])+abs(x[1]*x[5]+x[2]*x[6]))
  print(abs(x[1]+x[2])*abs(abs(x[3])+abs(x[4])))
}
```
```{r}
test_func(runif(6,min = -1))
```

```{r}
aiRrowdelta3 <- function(loss.prop,
                        total.loss,
                        aiRnet,
                        n) {


  vec.work <- vector("list", length(aiRnet))

  #g <- nrow(loss.prop)
  #row.work <- apply(loss.prop,2,mean)
  #additional.c <- apply(loss.prop*abs(loss.prop),2,mean)/((apply(loss.prop,2,mean)*abs(apply(loss.prop,2,mean))))
  #row.work <- additional.c*sqrt(length(row.work))*row.work*(abs(row.work/(total.loss)))
  row.work <- sqrt(length(loss.prop))*loss.prop*(abs(loss.prop/(total.loss)))
  for(j in n:1) { #use back propigation... record desired changes for each input to each node... record in $change.w $change.b
    w <- mat.opperation(x = abs(aiRnet[[j]]$weights), y = row.work, opperation = "*")
    #aiRnet[[j]]$change.w <- aiRnet[[j]]$change.w + w
    b <- abs(aiRnet[[j]]$bias)*row.work
    vec.work[[j]] <- list(w,b)
    names(vec.work[[j]]) <- c("change.w","change.b")
    #aiRnet[[j]]$change.b <- aiRnet[[j]]$change.b + b
    new.loss <- apply(w,1,mean)
      # data.work <- aiRtransform(data = data[,-index], aiRnet = aiRnet, n = j-1)
      # new.loss <- sqrt(length(new.loss))*new.loss*(abs(new.loss))/(sum(abs(new.loss)))
      # loss.work <- mat.opperation(x = as.matrix(data.work), y = new.loss, opperation = "*")
      # new.loss <- apply(loss.work, 2, mean)
      #additional.c <- apply(loss.work*abs(loss.work),2,mean)/((apply(loss.work,2,mean)*abs(apply(loss.work,2,mean))))
      #additional.c <- apply(as.data.frame(w)*abs(as.data.frame(w)),1,mean)/((apply(as.data.frame(w),1,mean)*abs(apply(as.data.frame(w),1,mean))))
      row.work <- sqrt(length(new.loss))*new.loss*(abs(new.loss)/sum(abs(new.loss)))


  }
  return(vec.work)
}
```

```{r}
get_layer_change <- function(x, layer) {
  return(x[[layer]])
}
```

```{r}
average_list <- function(x) {
  x.work <- x[[1]]
  for(i in 2:length(x)) {
    x.work <- x.work + x[[i]]
  }
  x.work <- x.work/length(x)
  return(x.work)
}
```

```{r}
apply_average <- function(x,aiRlayer, w.b) {
  a <- average_list(lapply(lapply(x,get_layer_change, layer = aiRlayer), get_layer_change, layer = w.b))
  return(a)
}

```
```{r}
get_change_average <- function(apply.test, n) {
  list.work <- vector("list",n)
  for(i in 1:n) {
    new.w <- apply_average(x = apply.test, aiRlayer = i, w.b = 1)
    new.b <- apply_average(x = apply.test, aiRlayer = i, w.b = 2)
    list.work[[i]] <- list(new.w,new.b)
    names(list.work[[i]]) <- c("change.w","change.b")
  }
  return(list.work)
}

```
```{r}
test1 <- function() {
  for(i in 1:length(loss$row.loss)) { #for each input, start with loss
      aiRnet1 <- aiRrowdelta1(loss.prop = loss$loss.prop[i,],
                            total.loss = loss$total.loss,
                            aiRnet = aiRnet1,
                            n = t)}                                                      

for(i in 1:t) {
  aiRnet1[[i]]$change.w <- aiRnet1[[i]]$change.w/s
  aiRnet1[[i]]$change.b <- aiRnet1[[i]]$change.b/s
}
  return(aiRnet1)
}
```

```{r}
test2 <- function(aiRnet2) {
  apply.test <- apply(X = loss$loss.prop,MARGIN = 1,FUN = aiRrowdelta3, total.loss = loss$total.loss, aiRnet = aiRnet2, n = t)
  test <- get_change_average(apply.test = apply.test, n = length(aiRnet2))
  for(i in 1:length(aiRnet2)) {
    aiRnet2[[i]]$change.w <- test[[i]]$change.w
    aiRnet2[[i]]$change.b <- test[[i]]$change.b
  }
  return(aiRnet2)
}
```

```{r}
test3 <- function() {
  mat <- cut2groups(loss.prop = loss$loss.prop)
  for(i in 1:nrow(mat)) {
    aiRnet2 <- aiRrowdelta1(loss.prop = mat[i,], total.loss = loss$total.loss, aiRnet = aiRnet2, n = t)
  }

  for(i in 1:t) {
  aiRnet2[[i]]$change.w <- aiRnet2[[i]]$change.w/s
  aiRnet2[[i]]$change.b <- aiRnet2[[i]]$change.b/s
}
  return(aiRnet2)
}
```

