---
title: "Testing"
author: "Justin L"
date: "4/4/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
library(ggplot2)
library(magrittr)
library(tidyr)
library(dplyr)
library(justinmisc)
library(reshape2)
library(aiR)
# library(gapminder)
# library(gganimate)
# library(animation)
```

```{r}
#Training data 1

set.seed(6227)
group1.x <- runif(n = 300)
group1.y <- runif(n = 300)
group2.x <- runif(n = 300, min = -1, max = .5)
group2.y <- runif(n = 300, min = -1, max = .1)

g1 <- cbind(group1.x,group1.y, rep("g1",300))
colnames(g1) <- c("x","y","group")
g2 <- cbind(group2.x,group2.y, rep("g2",300))
colnames(g2) <- c("x","y","group")

train <- as.data.frame(rbind(g1,g2))
train <- justinmisc::correct.mode(train,c("num","num","Factor"))
train$z <- runif(300)
ggplot(train, aes(x,y, color = group)) +
  geom_point()

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
mylayers <- aiRnet(c(2,4,2))
# layer1 <- aiRlayer(2,4)
# layer2 <- aiRlayer(4,2)
# mylayers <- list(layer1, layer2)
```


```{r}
# train <- rbind(train, data.frame(x = c(.7, .9, .6, -.7,-.9,-.6),
#                         y = c(-.7,-.6,-.9, .5, .3, .8),
#                         group = c("g2","g2","g2","g1","g1","g1"),
#                         z = c(.1,.2,.4,.5,.7,-.8)))
train <- train[,-4]
loss.aiR <- aiRrun(data = train,var.classify = "group",aiRnet = mylayers, sample.size = .5,cycles = 300,batch.size = 60)
```

```{r}
set.seed(6778)
system.time(loss.aiR <- aiRrun(data = train,var.classify = "group",aiRnet = mylayers, sample.size = .5,cycles = 300,batch.size = 60))
set.seed(6778)
system.time(loss.aiR <- aiRrun(data = train,var.classify = "group",aiRnet = mylayers, sample.size = .5,cycles = 300,batch.size = 60, test = TRUE))
```





```{r}
iteration <- as.numeric(rownames(loss.aiR$loss))
ggplot(data = loss.aiR$loss,aes(x = iteration)) +
  geom_point(aes(y = train,color = "train")) +
  geom_point(aes(y = train.error, color = "train.error")) +
  #geom_point(aes(y = test, color = "test")) +
  labs(list(y = "loss"))+
  coord_cartesian(ylim = c(min(loss.aiR$loss[!loss.aiR$loss==0]),max(loss.aiR$loss)))+
  theme(axis.text.x = element_text(angle = 90)) +
  scale_y_log10()
```



```{r}
# v <- function(data,
#               factor,
#               aiRnet,
#               range.size = 10000) {
#   index <- index.o.coln(vec = factor, v.size = 1, v.name = "factor", name.col = colnames(data))
#   new <- aiRactivation(data = data[,-index], aiRnet = aiRnet, range.size = range.size)
#   classify_obj <- aiRclassify(data = new$data_model, factor = index, aiRnet = aiRnet)
#   gg <- ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
#   geom_point(aes(color = as.factor(classify_obj$classify), alpha = classify_obj$node.max))
#   return(gg)
#               }
```

```{r}
new <- aiRactivation(data = train[,-3], aiRnet = loss.aiR$aiRnet, range.size = 10000)
```

```{r}
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer1[,1])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer1[,2])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer1[,3])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer1[,4])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
```
```{r}
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer2[,1])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = new$layer2[,2])) +
  scale_color_gradient2(low = "orange", mid = "white", high = "blue")
```

```{r}
classify_obj <- aiRclassify(data = new$data_model, factor = levels(train$group), aiRnet = loss.aiR$aiRnet)
```

```{r}
ggplot(as.data.frame(new$data_model), aes(x = x, y = y)) +
  geom_point(aes(color = as.factor(classify_obj$classify), alpha = classify_obj$node.max)) 
```

```{r}
aiRrate(data = train, factor = "group", aiRnet = loss.aiR$aiRnet)
```


```{r}
space.var <- aiRdevelop(data = train, var.classify = "group", aiRnet = mylayers, sample.size = 1, batch.size = 60, steps = 22)
  gg <- ggplot(data = space.var, aes(x = x, y = y, color = classify, alpha = node.max)) +
    geom_point() +
    facet_wrap(~step)
  gg

```


```{r}
#build > load all
#newaiR <- aiRnet(c(2,4,4,2))
aiRnet1 <- newaiR
aiRnet2 <- newaiR
t <- length(aiRnet1)
s <- 10
try.test <- train[sample(1:600,s),]



loss <- aiRloss(data = aiRtransform(data = try.test[,-3], aiRnet = aiRnet1),class.levels = levels(train[,3]),classify = try.test[,3])
additional.c <- apply(loss.prop^2,2,mean)/((apply(loss.prop,2,mean))^2)  # The proportion mean of squares to square of mean... (iteration of each row vs average each row)

    for(i in 1:length(loss$row.loss)) { #for each input, start with loss
      aiRnet1 <- aiRrowdelta(loss.prop = loss$loss.prop[i,],
                            row.loss = loss$row.loss[i],
                            total.loss = loss$total.loss,
                            aiRnet = aiRnet1,
                            n = t)
    }

mean.loss.prop <- apply(loss$loss.prop,2,mean)
mean.row.loss <- mean(loss$row.loss)
aiRnet2 <- aiRrowdelta2(loss.prop = loss$loss.prop, 
                       row.loss = loss$row.loss,
                       total.loss = loss$total.loss,
                       aiRnet = aiRnet2,
                       n = t, additional.c = additional.c)

for(i in 1:t) {
  aiRnet1[[i]]$change.w <- aiRnet1[[i]]$change.w/s
}
for(i in t:1) {
  print(aiRnet1[[i]]$change.w/aiRnet2[[i]]$change.w)
}

```

```{r}
aiRrowdelta <- function(loss.prop,
                        row.loss,
                        total.loss,
                        aiRnet,
                        n) {
  g <- nrow(loss.prop)
  row.work <- apply(loss.prop,2,mean)
  additional.c <- apply(loss.prop^2,2,mean)/((apply(loss.prop,2,mean))^2)
  row.work <- additional.c*sqrt(length(row.work))*row.work*(abs(row.work/(total.loss)))
  for(j in n:1) { #use back propigation... record desired changes for each input to each node... record in $change.w $change.b
    w <- mat.opperation(x = abs(aiRnet[[j]]$weights), y = row.work, opperation = "*")
    aiRnet[[j]]$change.w <- aiRnet[[j]]$change.w + w
    b <- abs(aiRnet[[j]]$bias)*row.work
    aiRnet[[j]]$change.b <- aiRnet[[j]]$change.b + b
    new.loss <- apply(w,1,mean)
    #additional.c <- (sum(apply(loss.prop,2,mean)^2))*(sum(abs(apply(loss.prop^2,1,sum)))/(g*(sum(apply(loss$loss.prop^2,1,sum)*abs(apply(loss$loss.prop^2,1,sum)))))) 
    row.work <- additional.c*sqrt(length(new.loss))*new.loss*(abs(new.loss)/sum(abs(new.loss)))
  }
  return(aiRnet)
}
```

