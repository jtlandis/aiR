# Hello, world!
#
# This is an example function named 'hello'
# which prints 'Hello, world!'.
#
# You can learn more about package authoring with RStudio at:
#
#   http://r-pkgs.had.co.nz/
#
# Some useful keyboard shortcuts for package authoring:
#
#   Build and Reload Package:  'Ctrl + Shift + B'
#   Check Package:             'Ctrl + Shift + E'
#   Test Package:              'Ctrl + Shift + T'


sigmoid <- function(x) {
  (1 / (1 + exp(-x)))
}


aiRlayer <- function(dim1,dim2) {
  weights <- matrix(runif(n = dim1*dim2, min = -10, max = 10), nrow = dim1, ncol = dim2)
  bias <- runif(n = dim2, min = -5, max = 5)

  layer <- list(weights, bias)
  names(layer) <- c("weights","bias")
  class(layer) <- "aiRlayer"
  return(layer)

}
#' @name aiRsubset
#'
#' #' @param train.method Method to train data. "Sample" to take a sample of values in data. "Factor"
#' @param batch.size Number between (0-1) that modifies how much of training data is used.
#' @param train.Factor Necessary when train.method set to "Factor". Assign as vector of length 2 in the following form
#' c("column.index/name","factor.level"). Can assign only column name or index but first level is chosen in this case.
#'
#' @return Row numbers to subset
aiRsubset <- function(x, train.method, batch.size, train.Factor = NULL) {
  type.train.method <- c("Sample","Factor")
  if(!is.element(train.method, type.train.method)) {
    stop("train.method must be \"Sample\" or \"Factor\"")
  }
  total.length <- nrow(x)
  if(train.method == "Sample") {
    n <- round(nrow(x)*batch.size,0)
    sample.rows <- sample(as.numeric(row.names(x)),n)
  } else if(train.method == "Factor") {
    if(is.null(train.Factor)) {
      stop("train.Factor must be assigned index or column name when train.method is set to \"Factor\"")
    }
    factor.index <- justinmisc::index.o.coln(vec = train.Factor[1], v.size = 1, v.name = "train.Factor", name.col = colnames(x))
    if(!is.factor(x[,factor.index])) {
      stop(paste("is.factor returned FALSE on column named \"",colnames(x)[factor.index],"\". Change column to a factor.",sep = ""))
    }
    if(length(train.Factor)==1) {
      warning("Only the factor column was specified in train.Factor. Assuming first level of training vector is training set.")
      x <- eval(parse(text = paste(sep = "","x[x$",colnames(x)[factor.index],"==",deparse(levels(x[,factor.index])[1]),",]")))
      n <- round(nrow(x)*batch.size,0)
      sample.rows <- sample(as.numeric(row.names(x)),n)
    } else if(length(train.Factor)==2) {
      if(!any(train.Factor %in% levels(x[,factor.index]))) {
        stop(paste(train.Factor[2]," is not a level of indicated column vector.", sep = ""))
      }
      if(!any(train.Factor %in% x[,factor.index])) {
        stop(paste(train.Factor[2]," is not contained in indicated column vector.", sep = ""))
      }
      x <- eval(parse(text = paste(sep = "","x[x$",colnames(x)[factor.index],"==\"",train.Factor[2],"\",]")))
      n <- round(nrow(x)*batch.size,0)
      sample.rows <- sample(as.numeric(row.names(x)),n)
    } else {
      stop("train.Factor must either be length 1 or 2.")
    }
  }
  sub <- seq(1,total.length) %in% sample.rows
  return(sub)
}
is.aiRlayer <- function(x) inherits(x, "aiRlayer")
#' @name aiRrun
#'
#' @param data Data frame that contains all named columns needed
#' @param var.classify index or column name of vector that contains classifying values
#' @param layers layers generated by aiRlayer
#' @param train.method Method to train data. "Sample" to take a sample of values in data. "Factor"
#' @param batch.size Number between (0-1) that modifies how much of training data is used.
#' @param train.Factor Necessary when train.method set to "Factor". Assign as vector of length 2 in the following form
#' c("column.index/name","factor.level"). Can assign only column name or index but first level is chosen in this case.
#' @param na.rm remove NAs, default set to TRUE. Function likely to fail with NAs
aiRrun <- function(data, var.classify, layers, train.method="Sample", batch.size=.5,train.Factor = NULL, na.rm=TRUE) {

  n <- length(layers)             #how many layers
  index <- justinmisc::index.o.coln(vec = var.classify, v.size = 1, v.name = "var.classify", name.col = colnames(data))   #index of classify column
  if(isTRUE(na.rm)) {
    data <- na.exclude(data)
  } else {
    warning("na.rm set to FALSE, NA values not sutable for matrix multiplication. Set NA to place holder value.")
  }
  #How much of data is training, what method to train against
  data.save <- data
  sample.rows <- aiRsubset(x = data, train.method = train.method, batch.size = batch.size, train.Factor = train.Factor)

  data.train <- data[sample.rows,]
  data.test <-  data[!sample.rows,]
  classify <- data.save[,index]
  classify.train <- classify[sample.rows]
  classify.test <- classify[!sample.rows]
  data.train <- sigmoid(data.train[,-index])
  for(i in 1:n) {   #Transform data through layers
    data.train <- as.matrix(data.train )%*%layers[[i]]$weights
    data.train <- data.train + layers[[i]]$bias
    data.train <- sigmoid(data.train )
  }

  browser()
  #classification matrix
  class.mat <- diag(nrow = ncol(layers[[length(layers)]]$weights),ncol = ncol(layers[[length(layers)]]$weights))
  correct.train <- class.mat[classify.train,]
  loss.prop <- (apply((correct.train - data.train),2,neg.exp)) #squared loss, directional (negative used)
  row.loss <- apply(abs(loss.prop),1,sum)
  total.loss <- sum(loss.prop)

 #prop <- (correct.train - data.train)/data.train
  prop <- loss.prop/(matrix(rep(apply(X = abs(loss.prop), MARGIN = 2, sum), each = nrow(loss.prop)),ncol = ncol(loss.prop), nrow = nrow(loss.prop)))
 #prop <- prop/(matrix(rep(apply(X = abs(prop), MARGIN = 2, sum), each = nrow(prop)),ncol = ncol(prop), nrow = nrow(prop)))
 prop.node <- loss*loss.prop*prop
 node.size <- nrow(layer2$weights)
 prop.mat <- abs(as.data.frame(layer2$weights)/matrix(rep(apply(abs(as.data.frame(abs(layer2$weights))),2,sum), each = nrow(layer2$weights)),ncol = ncol(layer2$weights), nrow = nrow(layer2$weights)))
 l2 <- (as.data.frame(t(sqrt(node.size)*prop.mat))*(prop))
 layer2$weights <- l2 +(as.data.frame(layer2$weights))
 layer2$bias <- layer2$weights + prop.node

 prop.mat2 <- abs(as.data.frame(layer1$weights)/apply(abs(as.data.frame(layer1$weights)),2,sum))

  return(loss)

}

neg.exp <- function(x, power = 2) {
  .t <- x<0
  x <- x^(power)
  x[.t] <- -1*x[.t]
  return(x)
}
